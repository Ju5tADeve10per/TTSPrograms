import streamlit as st
import edge_tts
import asyncio
import base64
import uuid
import os
import subprocess
from langdetect import detect

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹å‡¦ç†
def clear_text():
    st.session_state["input_text"] = ""

# TTSç”Ÿæˆé–¢æ•°ï¼ˆç„¡éŸ³ã‚’è¿½åŠ ï¼‰
async def generate_tts(text, voice, rate):
    raw_filename = f"temp_raw_{uuid.uuid4().hex}.mp3"
    final_filename = f"temp_final_{uuid.uuid4().hex}.mp3"

    # éŸ³å£°ã‚’ç”Ÿæˆ
    communicate = edge_tts.Communicate(text, voice, rate=f"{'+' if rate >= 0 else ''}{rate}%")
    await communicate.save(raw_filename)

    # ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµåˆ
    command = [
        "ffmpeg",
        "-y", # ä¸Šæ›¸ãè¨±å¯
        "-i", "silence.mp3", # 3ç§’ç„¡éŸ³ï¼ˆäº‹å‰ã«ç”¨æ„ï¼‰
        "-i", raw_filename,
        "-filter_complex", "[0:0][1:0]concat=n=2:v=0:a=1[out]",
        "-map", "[out]",
        final_filename
    ]
    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    os.remove(raw_filename)
    return final_filename

# ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«UI
st.set_page_config(page_title="èª­ã¿ä¸Šã’ã‚¢ãƒ—ãƒª (TTS)", layout="centered")
st.title("ğŸ“¢ æ–‡ç« èª­ã¿ä¸Šã’ã‚¢ãƒ—ãƒª")

text = st.text_area("èª­ã¿ä¸Šã’ãŸã„æ–‡ç« ã‚’ã“ã“ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", height=300, key="input_text")
st.button("Clear", on_click=clear_text)

rate = st.slider("èª­ã¿ä¸Šã’é€Ÿåº¦ï¼ˆ%ï¼‰", -50, 50, 0)

voices = {
    "Nanami (æ—¥æœ¬èª) ": "ja-JP-NanamiNeural",
    "Keita (æ—¥æœ¬èª) ": "ja-JP-KeitaNeural",
    "Aria (è‹±èª) ": "en-US-AriaNeural",
    "Guy (è‹±èª) ": "en-US-GuyNeural",
}
voice_name = st.selectbox("èª­ã¿ä¸Šã’éŸ³å£°ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚", list(voices.keys()))
voice = voices[voice_name]

if st.button("ğŸ”Š éŸ³å£°ã‚’ç”Ÿæˆ"):
    if not text.strip():
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            detected_lang = detect(text)
        except:
            st.error("è¨€èªã®åˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        voice_lang = voice.split("-")[0]
        if detected_lang != voice_lang:
            st.error(f"å…¥åŠ›ã•ã‚ŒãŸè¨€èª ({detected_lang}) ã¨é¸æŠã•ã‚ŒãŸVoice ({voice_lang}) ã®è¨€èªãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
            st.stop()
        
        st.success("éŸ³å£°ã‚’ç”Ÿæˆä¸­ï¼ï¼ï¼å°‘ã—ãŠå¾…ã¡ãã ã•ã„ã€‚")

        filename = asyncio.run(generate_tts(text, voice, rate))

        with open(filename, "rb") as f:
            audio_bytes = f.read()
        b64_audio = base64.b64encode(audio_bytes).decode()
        os.remove(filename)

        audio_html = f"""
        <audio controls>
            <source src="data:audio/mp3;base64,{b64_audio}" type="audio/mp3">
            Your browser does not support the audio element.
        </audio>
        """
        st.markdown("### â–¶ï¸ ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã“ã“ã§å†ç”Ÿã§ãã¾ã™ï¼‰")
        st.components.v1.html(audio_html, height=80)