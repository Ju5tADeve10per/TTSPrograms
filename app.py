import streamlit as st
import edge_tts
import asyncio
import base64
import uuid
import os
from langdetect import detect
from pydub import AudioSegment

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹å‡¦ç†
def clear_text():
    st.session_state["input_text"] = ""

# TTSç”Ÿæˆé–¢æ•°ï¼ˆç„¡éŸ³ã‚’è¿½åŠ ï¼‰
async def generate_tts(text, voice, rate):
    filename = f"temp_{uuid.uuid4().hex}.mp3"
    # rateã®å½¢å¼ã‚’ç¬¦å·ã‚’ã¤ã‘ã¦èª¿æ•´
    communicate = edge_tts.Communicate(text, voice, rate=f"{'+' if rate >= 0 else ''}{rate}%")
    await communicate.save(filename)

    # ç„¡éŸ³ã‚’å…ˆé ­ã«è¿½åŠ ï¼ˆ3ç§’ï¼‰
    voice_audio = AudioSegment.from_file(filename, format="mp3")
    silence = AudioSegment.silent(duration=3000) # 3ç§’ã®ç„¡éŸ³
    combined = silence + voice_audio
    combined.export(filename, format="mp3")
    
    return filename

# ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒ¼ãƒ‰é–‹å§‹
st.set_page_config(page_title="èª­ã¿ä¸Šã’ã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ“¢ æ–‡ç« èª­ã¿ä¸Šã’ã‚¢ãƒ—ãƒª")

text = st.text_area("èª­ã¿ä¸Šã’ãŸã„æ–‡ç« ã‚’ã“ã“ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", height=300, key="input_text")

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
st.button("Clear", on_click=clear_text)

# é€Ÿåº¦ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
rate = st.slider("èª­ã¿ä¸Šã’é€Ÿåº¦ï¼ˆ%ï¼‰", -50, 50, 0)

# Voiceã®é¸æŠè‚¢ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¢—ã‚„ã›ã‚‹ï¼‰
voices = {
    "Nanami (æ—¥æœ¬èª) ": "ja-JP-NanamiNeural",
    "Keita (æ—¥æœ¬èª)": "ja-JP-KeitaNeural",
    "Aria (è‹±èª) ": "en-US-AriaNeural",
    "Guy (è‹±èª) ": "en-US-GuyNeural",
}
voice_name = st.selectbox("èª­ã¿ä¸Šã’éŸ³å£°ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚", list(voices.keys()))
voice = voices[voice_name]

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ”Š èª­ã¿ä¸Šã’é–‹å§‹"):
    if not text.strip():
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            detected_lang = detect(text)
        except:
            st.error("è¨€èªã®åˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # Voiceã®è¨€èªã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼š"ja-JP-NanamiNeural" -> "ja")
        voice_lang = voice.split("-")[0]
        
        if detected_lang != voice_lang:
            st.error(f"å…¥åŠ›ã•ã‚ŒãŸè¨€èª ({detected_lang}) ã¨é¸æŠã•ã‚ŒãŸVoice ({voice_lang}) ã®è¨€èªãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
            st.stop()
        
        st.success("éŸ³å£°ã‚’ç”Ÿæˆä¸­ï¼ï¼ï¼å°‘ã—ãŠå¾…ã¡ãã ã•ã„ã€‚")

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        filename = asyncio.run(generate_tts(text, voice, rate))

        # base64ã§HTMLã«åŸ‹ã‚è¾¼ã¿
        with open(filename, "rb") as f:
            audio_bytes = f.read()
        b64_audio = base64.b64encode(audio_bytes).decode()
        os.remove(filename)

        audio_html = f"""
        <audio controls>
            <source src="data:audio/mp3;base64,{b64_audio}" type="audio/mp3">
            Your browser does not support the audio element.
        </audio>
        """
        st.components.v1.html(audio_html, height=80)